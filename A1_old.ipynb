{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fead7d53",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9ea2cf",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "### Importing data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d5c1d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in WP : 0\n",
      "Missing values in BCP: 0\n",
      "Missing values in AR: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Reading csv-files into variables as DataFrames\n",
    "wp_raw = pd.read_csv('website-phishing.csv')\n",
    "bcp_raw = pd.read_csv('bcp.csv')\n",
    "ar_raw = pd.read_csv('arrhythmia.csv')\n",
    "\n",
    "# Replace ? with NaN\n",
    "wp_raw.replace('?', np.nan, inplace=True)\n",
    "bcp_raw.replace('?', np.nan, inplace=True)\n",
    "ar_raw.replace('?', np.nan, inplace=True)\n",
    "\n",
    "\n",
    "#Convert all values to float to find mean\n",
    "wp_raw = wp_raw.astype(float)\n",
    "bcp_raw = bcp_raw.astype(float)\n",
    "ar_raw = ar_raw.astype(float)\n",
    "\n",
    "\n",
    "#Fillin NaNs with mean of column\n",
    "wp = wp_raw.fillna(wp_raw.mean())\n",
    "bcp = bcp_raw.fillna(bcp_raw.mean())\n",
    "ar = ar_raw.fillna(ar_raw.mean())\n",
    "\n",
    "#Check for missing values\n",
    "wp_missing_values = wp.isna().sum().sum()\n",
    "bcp_missing_values = bcp.isna().sum().sum()\n",
    "ar_missing_values = ar.isna().sum().sum()\n",
    "\n",
    "print(\"Missing values in WP :\", wp_missing_values)\n",
    "print(\"Missing values in BCP:\", bcp_missing_values)\n",
    "print(\"Missing values in AR:\", ar_missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c80eaf",
   "metadata": {},
   "source": [
    "### Splitting data sets\n",
    "In this section I will split the data sets into training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8096928d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480      1.0\n",
      "10812   -1.0\n",
      "4064     1.0\n",
      "8225     1.0\n",
      "9432    -1.0\n",
      "        ... \n",
      "5734    -1.0\n",
      "5191    -1.0\n",
      "5390    -1.0\n",
      "860      1.0\n",
      "7270    -1.0\n",
      "Name:   Class , Length: 8844, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Define feature matrix and target variable\n",
    "X1 = wp.drop(columns=[\"  Class \"])\n",
    "y1 = wp[\"  Class \"]\n",
    "\n",
    "X2 = bcp.drop(columns=[\"Class\"])\n",
    "y2 = bcp[\"Class\"] \n",
    "\n",
    "X3 = ar.drop(columns=[\"class\"])\n",
    "y3 = ar[\"class\"]\n",
    "\n",
    "#Define training and test set\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=42)\n",
    "\n",
    "print(y1_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadddea6",
   "metadata": {},
   "source": [
    "## Implementation of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b273e55",
   "metadata": {},
   "source": [
    "### Entropy\n",
    "To compare the impurity before and after a split, I need a function for calculating entropy. Simply explained, entropy is a way of measuring disorder, and is used to measure the randomness in a set. The formula for entropy is: \n",
    "$$\n",
    "E(S) = \\sum_{i=1}^{c} - p_i \\log_2(p_i)\n",
    "$$\n",
    "\n",
    "Where S is the startset, and $p_i$ is the propability of value i. To avoid logarithm of zero, $1e-9$ is added to $p_i$. This addition is minor, but will make avoid numeric instability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92804c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate entropy\n",
    "import numpy as np\n",
    "\n",
    "def entropy(S):\n",
    "    p_i = S.value_counts()/S.shape[0]\n",
    "    e = np.sum(-p_i * np.log2(p_i + 1e-9))\n",
    "    return e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094dabcd",
   "metadata": {},
   "source": [
    "### Information Gain\n",
    "To evaluate the splits, I will calculate the entropy before and anfter the split. The difference will give me a measure of the information gain of the split. If the entropy is lower (less randomness in the subsets) after the split, the information gain will be positive. I want to choose the split that provides the highest information gain. The formula for information gain is: \n",
    "$$\n",
    "InformationGain= Entropy(S) - \\sum_{k} \\frac{|k|}{|S|}Entropy(k)\n",
    "$$\n",
    "\n",
    "Where S is the start set, and $k_i$ is the i-th subset. The fraction factor is weighting the entropy of each of the subsets based on the number of instances in the subset, compared with the total number of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "febd3db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate information gain\n",
    "def information_gain(S, splits):\n",
    "    #Entropy of start set\n",
    "    S_entropy = entropy(S)\n",
    "\n",
    "    #Entropy of split\n",
    "    split_entropy = 0\n",
    "    tot_samples = len(S)\n",
    "    for split in splits:\n",
    "        split_weight = len(split) / tot_samples\n",
    "        split_entropy += split_weight * entropy(split)\n",
    "    \n",
    "    ig = S_entropy - split_entropy\n",
    "    return ig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a926f25",
   "metadata": {},
   "source": [
    "## Implementing Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d7f4a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dce663",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''class DecisionTree:\n",
    "    def __init__(self, max_depth = None, max_split_per_feature = 10):\n",
    "        self.max_depth = max_depth\n",
    "        self.max_split_per_feature = max_split_per_feature\n",
    "\n",
    "    def make_split(self, X, y, feature_ids, thresholds):\n",
    "        splits = [] \n",
    "        for threshold in thresholds:\n",
    "            index = np.where(X[:,feature_ids] <= threshold)[0] #Split on threshold\n",
    "            splits.append(index, y[index]) #Add index and label thats lower than threshold\n",
    "        return splits \n",
    "    \n",
    "    def make_split(self, X, y, feature_ids, thresholds):\n",
    "        left_indices = np.where(X[:, feature_ids] <= thresholds)[0]\n",
    "        right_indices = np.where(X[:, feature_ids] > thresholds)[0]\n",
    "        return (left_indices, y[left_indices]), (right_indices, y[right_indices])\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        best_feature_ids, best_threshold, best_ig = None, None, -1\n",
    "        for feature_ids in range(X.shape[1]):\n",
    "\n",
    "            #Unique values in the feature\n",
    "            n_values = np.unique(X[:, feature_ids])\n",
    "\n",
    "            #Find thresholds\n",
    "            if len(n_values) > self.max_split_per_feature:\n",
    "                #Create possible thresholds. Eaqualy distributed between min and max values found in the feature-column\n",
    "                thresholds = np.linspace(min(n_values), max(n_values), self.max_split_per_feature)\n",
    "            else: \n",
    "                thresholds = n_values\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                splits = self.make_split(X,y, feature_ids, [threshold])\n",
    "                ig = information_gain(y, [split[1] for split in splits])\n",
    "                if ig > best_ig:\n",
    "                    best_ig = ig\n",
    "                    best_feature_ids = feature_ids\n",
    "                    best_threshold = threshold\n",
    "        return best_feature_ids, best_threshold\n",
    "\n",
    "    #Grow tree\n",
    "    def grow_tree(self, X, y, depth = 0):\n",
    "\n",
    "        #Stopping criteria\n",
    "        if depth == self.max_depth or len(np.unique(y)) == 1: #Max depth or leaf node\n",
    "            return np.argmax(np.bincount(y))\n",
    "        \n",
    "        best_feature_ids, best_threshold = self.best_split(X,y)\n",
    "        if best_feature_ids is None: #No ig in split\n",
    "            return np.argmax(np.bincount(y))\n",
    "        \n",
    "        #Recursivly grow tree\n",
    "        splits = self.make_split(X, y, best_feature_ids, [best_threshold])\n",
    "        branches = []\n",
    "        for split in splits:\n",
    "            if len(splits[0]) == 0:\n",
    "                branches.append(np.argmax(np.bincount(y)))\n",
    "            else: \n",
    "                branches.append(self.grow_tree(X[split[0], split[1], depth + 1]))\n",
    "        return (best_feature_ids, best_threshold, branches)\n",
    "    \n",
    "    #Fit model\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.tree = self.grow_tree(X_train.to_numpy(), y_train)\n",
    "\n",
    "    #Predict instance\n",
    "    def pred_instance(self, x, tree):\n",
    "        if isinstance(tree, int):\n",
    "            return tree\n",
    "        feature_ids, threshold, branches = tree\n",
    "        for i, branch in enumerate(branches):\n",
    "            if x[feature_ids] <= threshold[i]:\n",
    "                return self.pred_instance(x, branch)\n",
    "        return self.pred_instance(x, branches[-1])\n",
    "\n",
    "    #Predictions\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X.to_numpy():\n",
    "            predictions.append(self.pred_instance(x, self.tree))\n",
    "        return np.array(predictions)\n",
    "'''\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, max_split_per_feature=10):\n",
    "        self.max_depth = max_depth\n",
    "        self.max_split_per_feature = max_split_per_feature\n",
    "        self.tree = None\n",
    "\n",
    "    def make_split(self, X, y, feature_index, threshold):\n",
    "        left_indices = np.where(X[:, feature_index] <= threshold)[0]\n",
    "        right_indices = np.where(X[:, feature_index] > threshold)[0]\n",
    "        return (left_indices, y[left_indices]), (right_indices, y[right_indices])\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        best_feature_index, best_threshold, best_ig = None, None, -1\n",
    "        for feature_index in range(X.shape[1]):\n",
    "            unique_values = np.unique(X[:, feature_index])\n",
    "            if len(unique_values) > self.max_split_per_feature:\n",
    "                thresholds = np.linspace(min(unique_values), max(unique_values), self.max_split_per_feature)\n",
    "            else:\n",
    "                thresholds = unique_values[:-1]\n",
    "            for threshold in thresholds:\n",
    "                left_split, right_split = self.make_split(X, y, feature_index, threshold)\n",
    "                ig = information_gain(y, [left_split[1], right_split[1]])\n",
    "                if ig > best_ig:\n",
    "                    best_ig = ig\n",
    "                    best_feature_index = feature_index\n",
    "                    best_threshold = threshold\n",
    "        return best_feature_index, best_threshold\n",
    "\n",
    "    def grow_tree(self, X, y, depth=0):\n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            return np.argmax(np.bincount(y))\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return y[0]\n",
    "        best_feature_index, best_threshold = self.best_split(X, y)\n",
    "        if best_feature_index is None:\n",
    "            return np.argmax(np.bincount(y))\n",
    "        left_split, right_split = self.make_split(X, y, best_feature_index, best_threshold)\n",
    "        left_branch = self.grow_tree(X[left_split[0]], left_split[1], depth + 1)\n",
    "        right_branch = self.grow_tree(X[right_split[0]], right_split[1], depth + 1)\n",
    "        return (best_feature_index, best_threshold, left_branch, right_branch)\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.tree = self.grow_tree(X_train.to_numpy(), y_train)\n",
    "\n",
    "    def pred_instance(self, x, tree):\n",
    "        if isinstance(tree, int):\n",
    "            return tree\n",
    "        feature_index, threshold, left_branch, right_branch = tree\n",
    "\n",
    "        #Check that x is numerical\n",
    "        numeric_variable = True if x.dtypes != 'O' else False\n",
    "        if numeric_variable:\n",
    "            if x[feature_index] <= threshold:\n",
    "                return self.pred_instance(x, left_branch)\n",
    "            else:\n",
    "                return self.pred_instance(x, right_branch)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X.to_numpy():\n",
    "            predictions.append(self.pred_instance(x, self.tree))\n",
    "        return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a9d1c5fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[3, 35, 39, 70, 76, 88, 93, 96, 101, 103, 106, 107, 119, 131, 167, 173, 185, 218, 245, 248, 251, 252, 263, 267, 291, 299, 311, 316, 318, 335, 376, 379, 398, 407, 408, 410, 415, 416, 426, 434, 439, 440, 457, 465, 469, 483, 486, 513, 533, 577, 590, 605, 608, 621, 623, 624, 676, 708, 710, 738, 747, 761, 764, 777, 782, 794, 836, 839, 852, 856, 881, 883, 914, 932, 937, 958, 970, 971, 1010, 1026, 1039, 1053, 1056, 1087, 1107, 1123, 1142, 1145, 1156, 1157, 1178, 1180, 1183, 1188, 1190, 1195, 1206, 1217, 1245, 1247, 1261, 1277, 1281, 1282, 1297, 1320, 1347, 1351, 1360, 1373, 1402, 1413, 1427, 1453, 1454, 1488, 1496, 1533, 1566, 1579, 1593, 1597, 1608, 1660, 1670, 1684, 1688, 1692, 1703, 1740, 1783, 1785, 1793, 1803, 1807, 1835, 1839, 1851, 1864, 1886, 1915, 1952, 1953, 1964, 1971, 2012, 2020, 2039, 2107, 2108, 2109, 2124, 2128, 2138, 2140, 2150, 2152, 2168, 2174, 2184, 2191, 2210, 2221, 2232, 2236, 2239, 2245, 2254, 2271, 2301, 2315, 2317, 2319, 2348, 2372, 2389, 2390, 2391, 2392, 2405, 2407, 2417, 2425, 2459, 2464, 2473, 2498, 2531, 2534, 2588, 2595, 2613, 2614, 2629, 2648, 2678, 2680, 2685, 2709, 2751, 2754, 2791, 2815, 2818, 2865, 2874, 2894, 2909, 2922, 2929, 2930, 2932, 2947, 2960, 2996, 3000, 3006, 3011, 3050, 3058, 3060, 3061, 3078, 3082, 3107, 3125, 3131, 3133, 3146, 3160, 3184, 3204, 3206, 3207, 3219, 3231, 3244, 3251, 3264, 3265, 3274, 3288, 3295, 3307, 3315, 3316, 3329, 3352, 3369, 3378, 3393, 3396, 3413, 3418, 3424, 3464, 3465, 3469, 3509, 3527, 3538, 3544, 3570, 3573, 3574, 3614, 3621, 3647, 3656, 3669, 3679, 3680, 3689, 3693, 3753, 3755, 3781, 3833, 3834, 3838, 3842, 3884, 3891, 3921, 3933, 3946, 3948, 3952, 3958, 3971, 3979, 4001, 4004, 4010, 4023, 4026, 4028, 4031, 4043, 4047, 4053, 4139, 4148, 4189, 4193, 4217, 4245, 4253, 4256, 4264, 4279, 4291, 4315, 4329, 4337, 4341, 4342, 4344, 4352, 4366, 4373, 4374, 4376, 4377, 4385, 4397, 4401, 4403, 4411, 4417, 4421, 4457, 4474, 4504, 4525, 4580, 4605, 4607, 4614, 4618, 4640, 4685, 4710, 4718, 4740, 4755, 4768, 4782, 4791, 4793, 4808, 4828, 4850, 4852, 4885, 4889, 4918, 4921, 4934, 4957, 4982, 4989, 5006, 5007, 5009, 5011, 5026, 5027, 5030, 5034, 5082, 5098, 5114, 5123, 5133, 5155, 5165, 5210, 5245, 5254, 5265, 5302, 5303, 5306, 5350, 5358, 5369, 5389, 5391, 5397, 5399, 5412, 5414, 5425, 5440, 5456, 5474, 5484, 5489, 5496, 5500, 5501, 5514, 5515, 5516, 5532, 5553, 5559, 5579, 5609, 5629, 5632, 5640, 5651, 5674, 5683, 5689, 5697, 5703, 5719, 5729, 5730, 5731, 5736, 5747, 5748, 5756, 5773, 5798, 5807, 5825, 5829, 5849, 5856, 5865, 5874, 5885, 5931, 5932, 5937, 5960, 5968, 5998, 6013, 6070, 6080, 6085, 6109, 6133, 6135, 6141, 6211, 6227, 6286, 6319, 6330, 6355, 6369, 6390, 6408, 6434, 6444, 6448, 6462, 6472, 6478, 6492, 6512, 6536, 6553, 6558, 6568, 6582, 6592, 6596, 6636, 6651, 6658, 6662, 6663, 6664, 6671, 6686, 6690, 6691, 6697, 6713, 6774, 6778, 6791, 6800, 6802, 6803, 6805, 6849, 6865, 6885, 6912, 6915, 6958, 6992, 7018, 7025, 7036, 7047, 7048, 7058, 7067, 7072, 7074, 7095, 7108, 7145, 7200, 7203, 7207, 7212, 7222, 7223, 7234, 7235, 7244, 7254, 7258, 7268, 7286, 7299, 7302, 7315, 7319, 7382, 7386, 7388, 7464, 7474, 7495, 7497, 7499, 7522, 7533, 7538, 7562, 7589, 7607, 7619, 7623, 7632, 7642, 7671, 7681, 7712, 7731, 7748, 7752, 7754, 7755, 7760, 7772, 7784, 7799, 7859, 7905, 7923, 7932, 7936, 7942, 7969, 8013, 8014, 8015, 8043, 8062, 8063, 8072, 8079, 8081, 8093, 8141, 8145, 8149, 8163, 8176, 8184, 8196, 8205, 8217, 8243, 8246, 8262, 8274, 8283, 8304, 8328, 8353, 8358, 8361, 8367, 8371, 8379, 8382, 8405, 8426, 8430, 8431, 8437, 8475, 8483, 8517, 8532, 8558, 8565, 8605, 8617, 8621, 8622, 8630, 8651, 8658, 8672, 8683, 8709, 8710, 8721, 8742, 8747, 8751, 8759, 8767, 8797, 8802, 8822, 8834] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m tree \u001b[38;5;241m=\u001b[39m DecisionTree(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, max_split_per_feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Step 3: Train the decision tree model\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m tree\u001b[38;5;241m.\u001b[39mfit(X1_train, y1_train)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Step 4: Use the trained model to make predictions\u001b[39;00m\n\u001b[1;32m      9\u001b[0m predictions \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mpredict(X1_test)\n",
      "Cell \u001b[0;32mIn[63], line 126\u001b[0m, in \u001b[0;36mDecisionTree.fit\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_train, y_train):\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrow_tree(X_train\u001b[38;5;241m.\u001b[39mto_numpy(), y_train)\n",
      "Cell \u001b[0;32mIn[63], line 117\u001b[0m, in \u001b[0;36mDecisionTree.grow_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 117\u001b[0m best_feature_index, best_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_split(X, y)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_feature_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39margmax(np\u001b[38;5;241m.\u001b[39mbincount(y))\n",
      "Cell \u001b[0;32mIn[63], line 104\u001b[0m, in \u001b[0;36mDecisionTree.best_split\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    102\u001b[0m     thresholds \u001b[38;5;241m=\u001b[39m unique_values[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m thresholds:\n\u001b[0;32m--> 104\u001b[0m     left_split, right_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_split(X, y, feature_index, threshold)\n\u001b[1;32m    105\u001b[0m     ig \u001b[38;5;241m=\u001b[39m information_gain(y, [left_split[\u001b[38;5;241m1\u001b[39m], right_split[\u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ig \u001b[38;5;241m>\u001b[39m best_ig:\n",
      "Cell \u001b[0;32mIn[63], line 93\u001b[0m, in \u001b[0;36mDecisionTree.make_split\u001b[0;34m(self, X, y, feature_index, threshold)\u001b[0m\n\u001b[1;32m     91\u001b[0m left_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(X[:, feature_index] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m threshold)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     92\u001b[0m right_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(X[:, feature_index] \u001b[38;5;241m>\u001b[39m threshold)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (left_indices, y[left_indices]), (right_indices, y[right_indices])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1033\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_values(key)\n\u001b[0;32m-> 1033\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_with(key)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1068\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minteger\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;66;03m# We need to decide whether to treat this as a positional indexer\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;66;03m#  (i.e. self.iloc) or label-based (i.e. self.loc)\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_should_fallback_to_positional:\n\u001b[0;32m-> 1068\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc[key]\n\u001b[1;32m   1069\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1070\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[key]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1100\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1102\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1332\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1330\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_iterable(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1272\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1272\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_listlike_indexer(key, axis)\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1274\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1462\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1459\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1460\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1462\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, axis_name)\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: '[3, 35, 39, 70, 76, 88, 93, 96, 101, 103, 106, 107, 119, 131, 167, 173, 185, 218, 245, 248, 251, 252, 263, 267, 291, 299, 311, 316, 318, 335, 376, 379, 398, 407, 408, 410, 415, 416, 426, 434, 439, 440, 457, 465, 469, 483, 486, 513, 533, 577, 590, 605, 608, 621, 623, 624, 676, 708, 710, 738, 747, 761, 764, 777, 782, 794, 836, 839, 852, 856, 881, 883, 914, 932, 937, 958, 970, 971, 1010, 1026, 1039, 1053, 1056, 1087, 1107, 1123, 1142, 1145, 1156, 1157, 1178, 1180, 1183, 1188, 1190, 1195, 1206, 1217, 1245, 1247, 1261, 1277, 1281, 1282, 1297, 1320, 1347, 1351, 1360, 1373, 1402, 1413, 1427, 1453, 1454, 1488, 1496, 1533, 1566, 1579, 1593, 1597, 1608, 1660, 1670, 1684, 1688, 1692, 1703, 1740, 1783, 1785, 1793, 1803, 1807, 1835, 1839, 1851, 1864, 1886, 1915, 1952, 1953, 1964, 1971, 2012, 2020, 2039, 2107, 2108, 2109, 2124, 2128, 2138, 2140, 2150, 2152, 2168, 2174, 2184, 2191, 2210, 2221, 2232, 2236, 2239, 2245, 2254, 2271, 2301, 2315, 2317, 2319, 2348, 2372, 2389, 2390, 2391, 2392, 2405, 2407, 2417, 2425, 2459, 2464, 2473, 2498, 2531, 2534, 2588, 2595, 2613, 2614, 2629, 2648, 2678, 2680, 2685, 2709, 2751, 2754, 2791, 2815, 2818, 2865, 2874, 2894, 2909, 2922, 2929, 2930, 2932, 2947, 2960, 2996, 3000, 3006, 3011, 3050, 3058, 3060, 3061, 3078, 3082, 3107, 3125, 3131, 3133, 3146, 3160, 3184, 3204, 3206, 3207, 3219, 3231, 3244, 3251, 3264, 3265, 3274, 3288, 3295, 3307, 3315, 3316, 3329, 3352, 3369, 3378, 3393, 3396, 3413, 3418, 3424, 3464, 3465, 3469, 3509, 3527, 3538, 3544, 3570, 3573, 3574, 3614, 3621, 3647, 3656, 3669, 3679, 3680, 3689, 3693, 3753, 3755, 3781, 3833, 3834, 3838, 3842, 3884, 3891, 3921, 3933, 3946, 3948, 3952, 3958, 3971, 3979, 4001, 4004, 4010, 4023, 4026, 4028, 4031, 4043, 4047, 4053, 4139, 4148, 4189, 4193, 4217, 4245, 4253, 4256, 4264, 4279, 4291, 4315, 4329, 4337, 4341, 4342, 4344, 4352, 4366, 4373, 4374, 4376, 4377, 4385, 4397, 4401, 4403, 4411, 4417, 4421, 4457, 4474, 4504, 4525, 4580, 4605, 4607, 4614, 4618, 4640, 4685, 4710, 4718, 4740, 4755, 4768, 4782, 4791, 4793, 4808, 4828, 4850, 4852, 4885, 4889, 4918, 4921, 4934, 4957, 4982, 4989, 5006, 5007, 5009, 5011, 5026, 5027, 5030, 5034, 5082, 5098, 5114, 5123, 5133, 5155, 5165, 5210, 5245, 5254, 5265, 5302, 5303, 5306, 5350, 5358, 5369, 5389, 5391, 5397, 5399, 5412, 5414, 5425, 5440, 5456, 5474, 5484, 5489, 5496, 5500, 5501, 5514, 5515, 5516, 5532, 5553, 5559, 5579, 5609, 5629, 5632, 5640, 5651, 5674, 5683, 5689, 5697, 5703, 5719, 5729, 5730, 5731, 5736, 5747, 5748, 5756, 5773, 5798, 5807, 5825, 5829, 5849, 5856, 5865, 5874, 5885, 5931, 5932, 5937, 5960, 5968, 5998, 6013, 6070, 6080, 6085, 6109, 6133, 6135, 6141, 6211, 6227, 6286, 6319, 6330, 6355, 6369, 6390, 6408, 6434, 6444, 6448, 6462, 6472, 6478, 6492, 6512, 6536, 6553, 6558, 6568, 6582, 6592, 6596, 6636, 6651, 6658, 6662, 6663, 6664, 6671, 6686, 6690, 6691, 6697, 6713, 6774, 6778, 6791, 6800, 6802, 6803, 6805, 6849, 6865, 6885, 6912, 6915, 6958, 6992, 7018, 7025, 7036, 7047, 7048, 7058, 7067, 7072, 7074, 7095, 7108, 7145, 7200, 7203, 7207, 7212, 7222, 7223, 7234, 7235, 7244, 7254, 7258, 7268, 7286, 7299, 7302, 7315, 7319, 7382, 7386, 7388, 7464, 7474, 7495, 7497, 7499, 7522, 7533, 7538, 7562, 7589, 7607, 7619, 7623, 7632, 7642, 7671, 7681, 7712, 7731, 7748, 7752, 7754, 7755, 7760, 7772, 7784, 7799, 7859, 7905, 7923, 7932, 7936, 7942, 7969, 8013, 8014, 8015, 8043, 8062, 8063, 8072, 8079, 8081, 8093, 8141, 8145, 8149, 8163, 8176, 8184, 8196, 8205, 8217, 8243, 8246, 8262, 8274, 8283, 8304, 8328, 8353, 8358, 8361, 8367, 8371, 8379, 8382, 8405, 8426, 8430, 8431, 8437, 8475, 8483, 8517, 8532, 8558, 8565, 8605, 8617, 8621, 8622, 8630, 8651, 8658, 8672, 8683, 8709, 8710, 8721, 8742, 8747, 8751, 8759, 8767, 8797, 8802, 8822, 8834] not in index'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tree = DecisionTree(max_depth=3, max_split_per_feature=10)\n",
    "\n",
    "# Step 3: Train the decision tree model\n",
    "tree.fit(X1_train, y1_train)\n",
    "\n",
    "# Step 4: Use the trained model to make predictions\n",
    "predictions = tree.predict(X1_test)\n",
    "\n",
    "# Step 5: Calculate the accuracy\n",
    "accuracy = accuracy_score(y1_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a28390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cb61255",
   "metadata": {},
   "source": [
    "# NOTES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b61d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XDecisionStump:\n",
    "    def __init__(self):\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        self.prediction = None\n",
    "\n",
    "    def split_tree(self, X, y):\n",
    "        best_feature_index, best_threshold = get_best_split(X, y)\n",
    "        if best_feature_index is None:\n",
    "            return y.mode()[0]  # Majority class in leaf node\n",
    "        bol = X.iloc[:, best_feature_index] <= best_threshold\n",
    "        y_left = y[bol]\n",
    "        y_right = y[~bol]\n",
    "        if y_left.empty or y_right.empty:\n",
    "            return y.mode()[0]  # Majority class in leaf node\n",
    "        return (best_feature_index, best_threshold, y_left, y_right)\n",
    "    \n",
    "    def get_acc(y, left, right):\n",
    "        acc = -1\n",
    "        return acc\n",
    "    \n",
    "    def get_best_accuracy(self, X,y):\n",
    "        best_acc = -1\n",
    "        best_threshold = None\n",
    "        best_feature_index = None\n",
    "\n",
    "        for feature_id in range (0, X.shape[1]):\n",
    "            thresholds = np.unique(X.iloc[: ,feature_id].tolist())\n",
    "            for threshold_value in thresholds:\n",
    "                left, right = split(X,y,feature_id, threshold_value)\n",
    "                acc = self.get_acc(y,left,right)\n",
    "                if acc > best_acc:\n",
    "                    best_acc, best_threshold,best_feature_index = acc, threshold_value, feature_id\n",
    "\n",
    "        return best_feature_index, best_threshold\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        best_feature_index, best_threshold = self.get_best_accuracy(X,y)\n",
    "        bol = X.iloc[:, best_feature_index] <= best_threshold\n",
    "        y_left = y[bol]\n",
    "        y_right = y[~bol]\n",
    "        return (best_feature_index, best_threshold, y_left, y_right)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        best_score = float('inf')\n",
    "        for feature_index in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "            for threshold in thresholds:\n",
    "                y_left = y[X[:, feature_index] < threshold]\n",
    "                y_right = y[X[:, feature_index] >= threshold]\n",
    "                score = len(y_left) * self._impurity(y_left) + len(y_right) * self._impurity(y_right)\n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    self.feature_index = feature_index\n",
    "                    self.threshold = threshold\n",
    "                    self.prediction = np.round(y.mean())\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(X[:, self.feature_index] < self.threshold, self.prediction, 1 - self.prediction)\n",
    "\n",
    "    def _impurity(self, y):\n",
    "        p = np.mean(y)\n",
    "        return p * (1 - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c83a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XDecisionStump:\n",
    "    def __init__(self):\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        self.prediction = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        best_accuracy = 0\n",
    "\n",
    "        # Iterate over each feature and threshold to find the best split\n",
    "        for feature_index in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                # Make predictions based on the current feature and threshold\n",
    "                predictions = np.where(X[:, feature_index] <= threshold, 1, -1)\n",
    "\n",
    "                # Calculate accuracy\n",
    "                accuracy = np.mean(predictions == y)\n",
    "\n",
    "                # Update the best split if accuracy improves\n",
    "                if accuracy > best_accuracy:\n",
    "                    self.feature_index = feature_index\n",
    "                    self.threshold = threshold\n",
    "                    self.prediction = 1 if np.mean(y) >= 0.5 else -1\n",
    "                    best_accuracy = accuracy\n",
    "\n",
    "    def pred_instance(self, x, tree):\n",
    "        if isinstance(tree, int) or isinstance(tree, float):\n",
    "            return tree  # Return the predicted class directly\n",
    "        feature_index, threshold, left_branch, right_branch = tree\n",
    "        if float(x[feature_index]) <= float(threshold):\n",
    "            return self.pred_instance(x, left_branch)\n",
    "        else:\n",
    "            return self.pred_instance(x, right_branch)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X)\n",
    "        X = X.astype(float) \n",
    "        predictions = []\n",
    "        for _, x in X.iterrows():\n",
    "            predictions.append(self.pred_instance(x, self.tree))\n",
    "        return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2884980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class xDecisionStump:\n",
    "    def __init__(self):\n",
    "        self.feature_index = None\n",
    "        self.threshold = 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        best_accuracy = 0\n",
    "\n",
    "        # Iterate over each feature and threshold to find the best split\n",
    "        for feature_index in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                # Make predictions based on the current feature and threshold\n",
    "                predictions = np.where(X[:, feature_index] <= threshold, 1, -1)\n",
    "\n",
    "                # Calculate accuracy\n",
    "                accuracy = np.mean(predictions == y)\n",
    "\n",
    "                # Update the best split if accuracy improves\n",
    "                if accuracy > best_accuracy:\n",
    "                    self.feature_index = feature_index\n",
    "                    self.threshold = threshold\n",
    "                    best_accuracy = accuracy\n",
    "\n",
    "    def predict_instance(self, x):\n",
    "        if float(x[self.feature_index]) <= float(self.threshold):\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "        \n",
    "    \n",
    "    def xpredict(self, X):\n",
    "        predictions = []\n",
    "        for _, x in X.iterrows():\n",
    "            predictions.append(self.predict_instance(x))\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for _, x in X.iterrows():\n",
    "            predictions.append(self.predict_instance(x))\n",
    "        return np.array(predictions)\n",
    "    \n",
    "\n",
    "    def xpred_instance(self, x, tree):\n",
    "        if isinstance(tree, int) or isinstance(tree, float):\n",
    "            return tree  # Return the predicted class directly\n",
    "        feature_index, threshold, left_branch, right_branch = tree\n",
    "        if float(x[feature_index]) <= float(threshold):\n",
    "            return self.pred_instance(x, left_branch)\n",
    "        else:\n",
    "            return self.pred_instance(x, right_branch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75f3572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision stump\n",
    "stump1 = DecisionStump()\n",
    "stump2 = DecisionStump()\n",
    "stump3 = DecisionStump()\n",
    "\n",
    "# Fit the models\n",
    "stump1.fit(X1_train.values, y1_train.values)\n",
    "stump2.fit(X2_train.values, y2_train.values)\n",
    "stump3.fit(X3_train.values, y3_train.values)\n",
    "\n",
    "#Accuracy\n",
    "y1_pred = stump1.predict(X1_test.values)\n",
    "y2_pred = stump2.predict(X2_test.values)\n",
    "y3_pred = stump3.predict(X3_test.values)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "acc1 = accuracy(y1_test, y1_pred)\n",
    "acc2 = accuracy(y2_test, y2_pred)\n",
    "acc3 = accuracy(y3_test, y3_pred)\n",
    "\n",
    "print(\"Accuracy webiste-phising:\", acc1)\n",
    "print(\"Accuracy bcp:\", acc2)\n",
    "print(\"Accuracy: arrhythmia\", acc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff886633",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def grow_tree(self, X, y, depth=0):\n",
    "        # Stopping criteria\n",
    "        if depth == self.max_depth or len(np.unique(y)) == 1:\n",
    "            return y.mode()[0]  # Majority class in leaf node\n",
    "        best_feature_index, best_threshold = get_best_split(X, y)\n",
    "        if best_feature_index is None:\n",
    "            return y.mode()[0]  # Majority class in leaf node\n",
    "        bol = X.iloc[:, best_feature_index] <= best_threshold\n",
    "        y_left = y[bol]\n",
    "        y_right = y[~bol]\n",
    "        if y_left.empty or y_right.empty:\n",
    "            return y.mode()[0]  # Majority class in leaf node\n",
    "        left_tree = self.grow_tree(X[bol], y_left, depth + 1)\n",
    "        right_tree = self.grow_tree(X[~bol], y_right, depth + 1)\n",
    "        return (best_feature_index, best_threshold, left_tree, right_tree)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.tree = {}\n",
    "        for cls in self.classes:\n",
    "            self.tree[cls] = self.grow_tree(X, y)\n",
    "\n",
    "    def predict_instance(self, x, tree):\n",
    "        if isinstance(tree, int) or isinstance(tree, float):\n",
    "            return tree  # Return the predicted class directly\n",
    "        feature_index, threshold, left_branch, right_branch = tree\n",
    "        if float(x[feature_index]) <= float(threshold):\n",
    "            return self.predict_instance(x, left_branch)\n",
    "        else:\n",
    "            return self.predict_instance(x, right_branch)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for _, x in X.iterrows():\n",
    "            class_predictions = {}\n",
    "            for cls in self.classes:\n",
    "                class_predictions[cls] = self.predict_instance(x, self.tree[cls])\n",
    "            predictions.append(max(class_predictions, key=class_predictions.get))\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Decision Tree\n",
    "tree1 = DecisionTree(max_depth=2)\n",
    "tree2 = DecisionTree(max_depth=2)\n",
    "tree3 = DecisionTree(max_depth=2)\n",
    "\n",
    "# Fit the models\n",
    "tree1.fit(X1_train, y1_train)\n",
    "tree2.fit(X2_train, y2_train)\n",
    "tree3.fit(X3_train, y3_train)\n",
    "\n",
    "# Accuracy\n",
    "y1_pred = tree1.predict(X1_test)\n",
    "y2_pred = tree2.predict(X2_test)\n",
    "y3_pred = tree3.predict(X3_test)\n",
    "\n",
    "acc1 = accuracy(y1_test, y1_pred)\n",
    "acc2 = accuracy(y2_test, y2_pred)\n",
    "acc3 = accuracy(y3_test, y3_pred)\n",
    "\n",
    "print(\"Accuracy webiste-phising:\", acc1)\n",
    "print(\"Accuracy bcp:\", acc2)\n",
    "print(\"Accuracy: arrhythmia\", acc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4972321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrunedTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def grow_tree(self, X, y, depth=0):\n",
    "        if depth == self.max_depth or len(np.unique(y)) == 1:\n",
    "            return y.mode()[0]  # Majority class in leaf node\n",
    "        best_feature_index, best_threshold = get_best_split(X, y)\n",
    "        if best_feature_index is None:\n",
    "            return y.mode()[0]  # Majority class in leaf node\n",
    "        bol = X.iloc[:, best_feature_index] <= best_threshold\n",
    "        y_left = y[bol]\n",
    "        y_right = y[~bol]\n",
    "        if y_left.empty or y_right.empty:\n",
    "            return y.mode()[0]  # Majority class in leaf node\n",
    "        left_tree = self.grow_tree(X[bol], y_left, depth + 1)\n",
    "        right_tree = self.grow_tree(X[~bol], y_right, depth + 1)\n",
    "        return (best_feature_index, best_threshold, left_tree, right_tree)\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        self.tree = self.grow_tree(X, y)\n",
    "        if X_val is not None and y_val is not None:\n",
    "            self.post_prune(X_val, y_val)\n",
    "\n",
    "    def post_prune(self, X_val, y_val):\n",
    "        self.prune_node(X_val, y_val, self.tree)\n",
    "\n",
    "    def prune_node(self, X_val, y_val, node):\n",
    "        if isinstance(node, int):\n",
    "            return node  # Leaf node, no pruning\n",
    "\n",
    "        feature_index, threshold, left_branch, right_branch = node\n",
    "\n",
    "        # Recursively prune left and right branches\n",
    "        left_branch = self.prune_node(X_val, y_val, left_branch)\n",
    "        right_branch = self.prune_node(X_val, y_val, right_branch)\n",
    "\n",
    "        # Evaluate performance before and after pruning\n",
    "        pred_before_prune = self.predict(X_val, node)\n",
    "        pred_after_prune = self.predict(X_val, (feature_index, threshold))\n",
    "\n",
    "        # Calculate error before and after pruning\n",
    "        error_before_prune = np.sum(pred_before_prune != y_val) / len(y_val)\n",
    "        error_after_prune = np.sum(pred_after_prune != y_val) / len(y_val)\n",
    "\n",
    "        # Prune node if performance improves or does not significantly worsen\n",
    "        if error_after_prune <= error_before_prune:\n",
    "            return (feature_index, threshold, None, None)  # Prune node\n",
    "        else:\n",
    "            return node  # Keep node\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X)\n",
    "        X = X.astype(float) \n",
    "        predictions = []\n",
    "        for _, x in X.iterrows():\n",
    "            predictions.append(self.pred_instance(x, self.tree))\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def pred_instance(self, x, tree):\n",
    "        if isinstance(tree, int) or isinstance(tree, float):\n",
    "            return tree  # Return the predicted class directly\n",
    "        feature_index, threshold, left_branch, right_branch = tree\n",
    "        if float(x[feature_index]) <= float(threshold):\n",
    "            return self.pred_instance(x, left_branch)\n",
    "        else:\n",
    "            return self.pred_instance(x, right_branch)\n",
    "        \n",
    "#Pruned Tree\n",
    "pruned1 = PrunedTree(max_depth=5)\n",
    "pruned2 = PrunedTree(max_depth=5)\n",
    "pruned3 = PrunedTree(max_depth=5)\n",
    "\n",
    "#Fit the models\n",
    "pruned1.fit(X1_train, y1_train)\n",
    "pruned2.fit(X2_train, y2_train)\n",
    "pruned3.fit(X3_train, y3_train)\n",
    "\n",
    "#Accuracy\n",
    "y1_pred = pruned1.predict(X1_test)\n",
    "y2_pred = pruned2.predict(X2_test)\n",
    "y3_pred = pruned3.predict(X3_test)\n",
    "\n",
    "acc1 = accuracy(y1_test, y1_pred)\n",
    "acc2 = accuracy(y2_test, y2_pred)\n",
    "acc3 = accuracy(y3_test, y3_pred)\n",
    "\n",
    "print(\"Accuracy webiste-phising:\", acc1)\n",
    "print(\"Accuracy bcp:\", acc2)\n",
    "print(\"Accuracy: arrhythmia\", acc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9693a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionStump:\n",
    "    def __init__(self):\n",
    "        self.feature_index = None\n",
    "        self.threshold = None\n",
    "        self.class_labels = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        best_accuracy = 0\n",
    "\n",
    "        # Iterate over each feature and threshold to find the best split\n",
    "        for feature_index in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "\n",
    "            for threshold in thresholds:\n",
    "\n",
    "                predictions = np.where(X[:, feature_index] <= threshold, -y, y)\n",
    "\n",
    "                # Overall accuracy\n",
    "                accuracy = np.mean(predictions == y)\n",
    "\n",
    "                # Update the best split if accuracy improves\n",
    "                if accuracy > best_accuracy:\n",
    "                    self.feature_index = feature_index\n",
    "                    self.threshold = threshold\n",
    "                    best_accuracy = accuracy\n",
    "\n",
    "\n",
    "    def predict_instance(self, x):\n",
    "        if float(x[self.feature_index]) <= float(self.threshold):\n",
    "            return self.class_labels[0]\n",
    "        else:\n",
    "            return self.class_labels[1]\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for _, x in X.iterrows():\n",
    "            predictions.append(self.predict_instance(x))\n",
    "        return np.array(predictions)\n",
    "\n",
    "#Decision stump\n",
    "stump1 = DecisionStump()\n",
    "stump2 = DecisionStump()\n",
    "stump3 = DecisionStump()\n",
    "\n",
    "# Fit the models\n",
    "stump1.fit(X1_train.values, y1_train.values)\n",
    "stump2.fit(X2_train.values, y2_train.values)\n",
    "stump3.fit(X3_train.values, y3_train.values)\n",
    "\n",
    "# Set class labels\n",
    "stump1.class_labels = np.unique(y1_train.values)\n",
    "stump2.class_labels = np.unique(y2_train.values)\n",
    "stump3.class_labels = np.unique(y3_train.values)\n",
    "\n",
    "# Accuracy\n",
    "y1_pred = stump1.predict(X1_test.values)\n",
    "y2_pred = stump2.predict(X2_test.values)\n",
    "y3_pred = stump3.predict(X3_test.values)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "acc1_stump = accuracy(y1_test, y1_pred)\n",
    "acc2_stump = accuracy(y2_test, y2_pred)\n",
    "acc3_stump = accuracy(y3_test, y3_pred)\n",
    "\n",
    "print(\"Accuracy webiste-phising:\", acc1_stump)\n",
    "print(\"Accuracy bcp:\", acc2_stump)\n",
    "print(\"Accuracy: arrhythmia\", acc3_stump)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1066b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:    \n",
    "    def __init__(self):\n",
    "        self.tree = None\n",
    "        self.best_feature_index = None\n",
    "        self.threshold = None\n",
    "        self.class_labels = None\n",
    "\n",
    "    def grow_tree(self, X, y, depth=0):\n",
    "            \n",
    "            #Stopping criteria. Stop if leaf node\n",
    "            if len(np.unique(y)) == 1:\n",
    "                return y.mode()[0]  # Majority class in leaf node\n",
    "            \n",
    "            #Get the split with the highest information gain\n",
    "            self.best_feature_index, self.best_threshold = get_best_split(X, y)\n",
    "\n",
    "            #If no split provides information gain -> leaf node\n",
    "            if self.best_feature_index is None:\n",
    "                return y.mode()[0]  # Majority class in leaf node\n",
    "            \n",
    "            #Split the date into left and right node based on best feature and corresponding threshold\n",
    "            bol = X.iloc[:, self.best_feature_index] <= self.best_threshold\n",
    "            y_left = y[bol]\n",
    "            y_right = y[~bol]\n",
    "\n",
    "            #If all samples are in one node -> leaf node\n",
    "            if y_left.empty or y_right.empty:\n",
    "                return y.mode()[0]  # Majority class in leaf node\n",
    "            \n",
    "            #If not, grow three further\n",
    "            left_tree = self.grow_tree(X[bol], y_left, depth + 1)\n",
    "            right_tree = self.grow_tree(X[~bol], y_right, depth + 1)\n",
    "\n",
    "            #Return splitting feature, threshold, left and right node\n",
    "            return (self.best_feature_index, self.best_threshold, left_tree, right_tree)\n",
    "\n",
    "    #Fit tree to data\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self.grow_tree(X, y)\n",
    "\n",
    "    #Predict one of the two first classes\n",
    "    def xpredict_instance(self, x):\n",
    "        if float(x[self.feature_index]) <= float(self.threshold):\n",
    "            return self.class_labels[0]\n",
    "        else:\n",
    "            return self.class_labels[1]\n",
    "        \n",
    "    def pred_instance(self, x, tree):\n",
    "        if isinstance(tree, int) or isinstance(tree, float):\n",
    "            return tree  # Return the predicted class directly\n",
    "        feature_index, threshold, left_branch, right_branch = tree\n",
    "        if float(x[feature_index]) <= float(threshold):\n",
    "            return self.pred_instance(x, left_branch)\n",
    "        else:\n",
    "            return self.pred_instance(x, right_branch)\n",
    "\n",
    "    def xpredict(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for _, x in X.iterrows():\n",
    "            predictions.append(self.predict_instance(x))\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def pred_instance(self, x, tree):\n",
    "        if isinstance(tree, int) or isinstance(tree, float):\n",
    "            return tree  # Return the predicted class directly\n",
    "        feature_index, threshold, left_branch, right_branch = tree\n",
    "        if float(x[feature_index]) <= float(threshold):\n",
    "            return self.pred_instance(x, left_branch)\n",
    "        else:\n",
    "            return self.pred_instance(x, right_branch)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X)\n",
    "        X = X.astype(float) \n",
    "        predictions = []\n",
    "        for _, x in X.iterrows():\n",
    "            predictions.append(self.pred_instance(x, self.tree))\n",
    "        return np.array(predictions)\n",
    "#########################################################################################\n",
    "\n",
    "class xDecisionTree:    \n",
    "    def __init__(self):\n",
    "        self.tree = None\n",
    "\n",
    "    def grow_tree(self, X, y, depth=0):\n",
    "            \n",
    "            #Stopping criteria\n",
    "            if len(np.unique(y)) == 1:\n",
    "                return y.mode()[0]  # Majority class in leaf node\n",
    "            \n",
    "            best_feature_index, best_threshold = get_best_split(X, y)\n",
    "            if best_feature_index is None:\n",
    "                return y.mode()[0]  # Majority class in leaf node\n",
    "            bol = X.iloc[:, best_feature_index] <= best_threshold\n",
    "            y_left = y[bol]\n",
    "            y_right = y[~bol]\n",
    "            if y_left.empty or y_right.empty:\n",
    "                return y.mode()[0]  # Majority class in leaf node\n",
    "            left_tree = self.grow_tree(X[bol], y_left, depth + 1)\n",
    "            right_tree = self.grow_tree(X[~bol], y_right, depth + 1)\n",
    "            return (best_feature_index, best_threshold, left_tree, right_tree)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self.grow_tree(X, y)\n",
    "\n",
    "    def pred_instance(self, x, tree):\n",
    "        if isinstance(tree, int) or isinstance(tree, float):\n",
    "            return tree  # Return the predicted class directly\n",
    "        feature_index, threshold, left_branch, right_branch = tree\n",
    "        if float(x[feature_index]) <= float(threshold):\n",
    "            return self.pred_instance(x, left_branch)\n",
    "        else:\n",
    "            return self.pred_instance(x, right_branch)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X)\n",
    "        X = X.astype(float) \n",
    "        predictions = []\n",
    "        for _, x in X.iterrows():\n",
    "            predictions.append(self.pred_instance(x, self.tree))\n",
    "        return np.array(predictions)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ba945",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Webiste-phising\n",
    "tree1 = DecisionTree()   \n",
    "tree1.fit(X1_train, y1_train)\n",
    "y1_pred = tree1.predict(X1_test)\n",
    "acc1_tree = np.mean(y1_test == y1_pred)\n",
    "print(\"Accuracy webiste-phising:\", acc1_tree)\n",
    "\n",
    "#BCP\n",
    "tree2 = DecisionTree()\n",
    "tree2.fit(X2_train, y2_train)\n",
    "y2_pred = tree2.predict(X2_test)\n",
    "acc2_tree = np.mean(y2_test == y2_pred)\n",
    "print(\"Accuracy bcp:\", acc2_tree)\n",
    "\n",
    "#Arrhythmia\n",
    "tree3 = DecisionTree()\n",
    "tree3.fit(X3_train, y3_train)\n",
    "y3_pred = tree3.predict(X3_test)\n",
    "acc3_tree = np.mean(y3_test == y3_pred)\n",
    "print(\"Accuracy: arrhythmia\", acc3_tree)\n",
    "'''\n",
    "\n",
    "'''\n",
    "# Pruned Tree\n",
    "pruned1 = PrunedTree(max_depth=5, min_samples_split=5)\n",
    "pruned2 = PrunedTree(max_depth=5, min_samples_split=5)\n",
    "pruned3 = PrunedTree(max_depth=5, min_samples_split=5)\n",
    "\n",
    "# Fit the models\n",
    "pruned1.fit(X1_train, y1_train)\n",
    "pruned2.fit(X2_train, y2_train)\n",
    "pruned3.fit(X3_train, y3_train)\n",
    "\n",
    "# Accuracy\n",
    "y1_pred = pruned1.predict(X1_test)\n",
    "y2_pred = pruned2.predict(X2_test)\n",
    "y3_pred = pruned3.predict(X3_test)\n",
    "\n",
    "acc1_pruned = accuracy(y1_test, y1_pred)\n",
    "acc2_pruned = accuracy(y2_test, y2_pred)\n",
    "acc3_pruned = accuracy(y3_test, y3_pred)\n",
    "\n",
    "print(\"Accuracy webiste-phising:\", acc1_pruned)\n",
    "print(\"Accuracy bcp:\", acc2_pruned)\n",
    "print(\"Accuracy: arrhythmia\", acc3_pruned)'''\n",
    "\n",
    "'''class PrunedTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def grow_tree(self, X, y, depth=0):\n",
    "        if depth == self.max_depth or len(np.unique(y)) == 1:\n",
    "            return y.mode()[0]  # Majority class in leaf node\n",
    "        best_feature_index, best_threshold = get_best_split(X, y)\n",
    "        if best_feature_index is None:\n",
    "            return y.mode()[0]  # Majority class in leaf node\n",
    "        bol = X.iloc[:, best_feature_index] <= best_threshold\n",
    "        y_left = y[bol]\n",
    "        y_right = y[~bol]\n",
    "        if y_left.empty or y_right.empty:\n",
    "            return y.mode()[0]  # Majority class in leaf node\n",
    "        left_tree = self.grow_tree(X[bol], y_left, depth + 1)\n",
    "        right_tree = self.grow_tree(X[~bol], y_right, depth + 1)\n",
    "        return (best_feature_index, best_threshold, left_tree, right_tree)\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        self.tree = self.grow_tree(X, y)\n",
    "        if X_val is not None and y_val is not None:\n",
    "            self.post_prune(X_val, y_val)\n",
    "\n",
    "    def post_prune(self, X_val, y_val):\n",
    "        self.prune_node(X_val, y_val, self.tree)\n",
    "\n",
    "    def prune_node(self, X_val, y_val, node):\n",
    "        if isinstance(node, int):\n",
    "            return node  # Leaf node, no pruning\n",
    "\n",
    "        feature_index, threshold, left_branch, right_branch = node\n",
    "\n",
    "        # Recursively prune left and right branches\n",
    "        left_branch = self.prune_node(X_val, y_val, left_branch)\n",
    "        right_branch = self.prune_node(X_val, y_val, right_branch)\n",
    "\n",
    "        # Evaluate performance before and after pruning\n",
    "        pred_before_prune = self.predict(X_val, node)\n",
    "        pred_after_prune = self.predict(X_val, (feature_index, threshold))\n",
    "\n",
    "        # Calculate error before and after pruning\n",
    "        error_before_prune = np.sum(pred_before_prune != y_val) / len(y_val)\n",
    "        error_after_prune = np.sum(pred_after_prune != y_val) / len(y_val)\n",
    "\n",
    "        # Prune node if performance improves or does not significantly worsen\n",
    "        if error_after_prune <= error_before_prune:\n",
    "            return (feature_index, threshold, None, None)  # Prune node\n",
    "        else:\n",
    "            return node  # Keep node\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X)\n",
    "        X = X.astype(float) \n",
    "        predictions = []\n",
    "        for _, x in X.iterrows():\n",
    "            predictions.append(self.pred_instance(x, self.tree))\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def pred_instance(self, x, tree):\n",
    "        if isinstance(tree, int) or isinstance(tree, float):\n",
    "            return tree  # Return the predicted class directly\n",
    "        feature_index, threshold, left_branch, right_branch = tree\n",
    "        if float(x[feature_index]) <= float(threshold):\n",
    "            return self.pred_instance(x, left_branch)\n",
    "        else:\n",
    "            return self.pred_instance(x, right_branch)\n",
    "        \n",
    "#Pruned Tree\n",
    "pruned1 = PrunedTree(max_depth=5)\n",
    "pruned2 = PrunedTree(max_depth=5)\n",
    "pruned3 = PrunedTree(max_depth=5)\n",
    "\n",
    "#Fit the models\n",
    "pruned1.fit(X1_train, y1_train)\n",
    "pruned2.fit(X2_train, y2_train)\n",
    "pruned3.fit(X3_train, y3_train)\n",
    "\n",
    "#Accuracy\n",
    "y1_pred = pruned1.predict(X1_test)\n",
    "y2_pred = pruned2.predict(X2_test)\n",
    "y3_pred = pruned3.predict(X3_test)\n",
    "\n",
    "acc1 = np.mean(y1_test == y1_pred)\n",
    "acc2 = np.mean(y2_test == y2_pred)\n",
    "acc3 = np.mean(y3_test == y3_pred)\n",
    "\n",
    "print(\"Accuracy webiste-phising:\", acc1)\n",
    "print(\"Accuracy bcp:\", acc2)\n",
    "print(\"Accuracy: arrhythmia\", acc3)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3ff463",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:    \n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def grow_tree(self, X, y, depth=0):\n",
    "            \n",
    "            #Stopping criteria\n",
    "            if depth == self.max_depth or len(np.unique(y)) == 1:\n",
    "                return y.mode()[0]  # Majority class in leaf node\n",
    "            best_feature_index, best_threshold = get_best_split(X, y)\n",
    "            if best_feature_index is None:\n",
    "                return y.mode()[0]  # Majority class in leaf node\n",
    "            bol = X.iloc[:, best_feature_index] <= best_threshold\n",
    "            y_left = y[bol]\n",
    "            y_right = y[~bol]\n",
    "            if y_left.empty or y_right.empty:\n",
    "                return y.mode()[0]  # Majority class in leaf node\n",
    "            left_tree = self.grow_tree(X[bol], y_left, depth + 1)\n",
    "            right_tree = self.grow_tree(X[~bol], y_right, depth + 1)\n",
    "            return (best_feature_index, best_threshold, left_tree, right_tree)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self.grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for _, x in X.iterrows():\n",
    "            predictions.append(self.pred_instance(x, self.tree))\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def pred_instance(self, x, tree):\n",
    "        if isinstance(tree, np.int64):\n",
    "            return tree  # Return the predicted class directly\n",
    "        feature_index, threshold, left_branch, right_branch = tree\n",
    "        if float(x[feature_index]) <= float(threshold):\n",
    "            return self.pred_instance(x, left_branch)\n",
    "        else:\n",
    "            return self.pred_instance(x, right_branch)\n",
    "\n",
    "#Webiste-phising\n",
    "tree1 = DecisionTree()   \n",
    "tree1.fit(X1_train, y1_train)\n",
    "y1_pred = tree1.predict(X1_test)\n",
    "acc1_tree = np.mean(y1_test == y1_pred)\n",
    "print(\"Accuracy webiste-phising:\", acc1_tree)\n",
    "\n",
    "#BCP\n",
    "tree2 = DecisionTree()\n",
    "tree2.fit(X2_train, y2_train)\n",
    "y2_pred = tree2.predict(X2_test)\n",
    "acc2_tree = np.mean(y2_test == y2_pred)\n",
    "print(\"Accuracy bcp:\", acc2_tree)\n",
    "\n",
    "#Arrhythmia\n",
    "tree3 = DecisionTree()\n",
    "tree3.fit(X3_train, y3_train)\n",
    "y3_pred = tree3.predict(X3_test)\n",
    "acc3_tree = np.mean(y3_test == y3_pred)\n",
    "print(\"Accuracy: arrhythmia\", acc3_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aac9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''class PrunedTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def grow_tree(self, X, y, depth=0):\n",
    "        if len(np.unique(y)) == 1 or (self.max_depth is not None and depth == self.max_depth):\n",
    "            return y.mode()[0]  # Majority class in leaf node\n",
    "\n",
    "        best_feature_index, best_threshold = get_best_split(X, y)\n",
    "        if best_feature_index is None:\n",
    "            return y.mode()[0]  # Majority class in leaf node\n",
    "\n",
    "        left_indices = X.iloc[:, best_feature_index] <= best_threshold\n",
    "        right_indices = ~left_indices\n",
    "\n",
    "        left_tree = self.grow_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_tree = self.grow_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return (best_feature_index, best_threshold, left_tree, right_tree)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self.grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for _, x in X.iterrows():\n",
    "            predictions.append(self.pred_instance(x, self.tree))\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def pred_instance(self, x, tree):\n",
    "        if isinstance(tree, np.int64):\n",
    "            return tree  # Return the predicted class directly\n",
    "        feature_index, threshold, left_branch, right_branch = tree\n",
    "        if float(x[feature_index]) <= float(threshold):\n",
    "            return self.pred_instance(x, left_branch)\n",
    "        else:\n",
    "            return self.pred_instance(x, right_branch)\n",
    "\n",
    "# Pruned Tree\n",
    "pruned1 = PrunedTree(max_depth=5)\n",
    "pruned1.fit(X1_train, y1_train)\n",
    "y1_pred = pruned1.predict(X1_test.values)\n",
    "acc1_pruned = np.mean(y1_test == y1_pred)\n",
    "print(\"Accuracy webiste-phising:\", acc1_pruned)\n",
    "\n",
    "\n",
    "pruned2 = PrunedTree(max_depth=5)\n",
    "pruned2.fit(X2_train, y2_train)\n",
    "y2_pred = pruned2.predict(X2_test)\n",
    "acc2_pruned = np.mean(y2_test == y2_pred)\n",
    "print(\"Accuracy bcp:\", acc2_pruned)\n",
    "\n",
    "\n",
    "pruned3 = PrunedTree(max_depth=5)\n",
    "pruned3.fit(X3_train, y3_train)\n",
    "y3_pred = pruned3.predict(X3_test)\n",
    "acc3_pruned = np.mean(y3_test == y3_pred)\n",
    "print(\"Accuracy: arrhythmia\", acc3_pruned)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
